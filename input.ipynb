{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270, 4), (129, 4))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "csv_dir = \"./dataset_csv/\"\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "train_df = pd.read_csv(\"/media/nfs/LN/CAMELYON16/train_slides.csv\")\n",
    "test_df = pd.read_csv(\"/media/nfs/LN/CAMELYON16/test_slides.csv\")\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_dir = \"/media/nfs/LN/CAMELYON16/patches/\"\n",
    "patch_dir_normal = \"/media/nfs/LN/CAMELYON16/SegPatches_224p/patches/\"\n",
    "patch_list = [i[:-3] for i in os.listdir(patch_dir)]\n",
    "normal_tests = list(test_df[\"slide_id\"][~test_df[\"slide_id\"].isin(patch_list)].values)\n",
    "normal_trains = list(train_df[\"slide_id\"][~train_df[\"slide_id\"].isin(patch_list)].values)\n",
    "add_list = [i+\".h5\" for i in normal_tests+normal_trains if i+\".h5\" in os.listdir(patch_dir_normal)]\n",
    "miss_list = [i+\".h5\" for i in normal_tests+normal_trains if i+\".h5\" not in os.listdir(patch_dir_normal)]\n",
    "len(add_list), len(miss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normal_027.h5', 'normal_045.h5']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"label\"][test_df[\"slide_id\"].isin([i[:-3] for i in  add_list])].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for file in add_list:\n",
    "    shutil.copyfile(patch_dir_normal + file, patch_dir + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((268, 4), (129, 4))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_dir = \"/media/nfs/LN/CAMELYON16/patches/\"\n",
    "patch_list = [i[:-3] for i in os.listdir(patch_dir)]\n",
    "train_df = train_df[train_df[\"slide_id\"].isin(patch_list)]\n",
    "test_df = test_df[test_df[\"slide_id\"].isin(patch_list)]\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((397, 2), 6, 188603)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from h5py import File\n",
    "\n",
    "nb_patches = []\n",
    "for i in os.listdir(patch_dir):\n",
    "    with File(patch_dir+i, \"r\") as hf:\n",
    "        coords = np.array(hf[\"coords\"])\n",
    "    nb_patches.append([i[:-3], len(coords)])\n",
    "    \n",
    "patch_df = pd.DataFrame(nb_patches, columns=[\"slide_id\", \"nb_patches\"])\n",
    "patch_df.shape, patch_df[\"nb_patches\"].min(), patch_df[\"nb_patches\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((268, 5), (129, 5), False, False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.merge(train_df, patch_df, on=\"slide_id\")\n",
    "test_df = pd.merge(test_df, patch_df, on=\"slide_id\")\n",
    "train_df.shape, test_df.shape, train_df.isna().any().any(), test_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_id</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "      <th>case_id</th>\n",
       "      <th>nb_patches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal_001</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal_001</td>\n",
       "      <td>8810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal_002</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal_002</td>\n",
       "      <td>11605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal_003</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal_003</td>\n",
       "      <td>27299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal_004</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal_004</td>\n",
       "      <td>6322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal_005</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal_005</td>\n",
       "      <td>8766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tumor_107</td>\n",
       "      <td>1</td>\n",
       "      <td>micro</td>\n",
       "      <td>tumor_107</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tumor_108</td>\n",
       "      <td>1</td>\n",
       "      <td>macro</td>\n",
       "      <td>tumor_108</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tumor_109</td>\n",
       "      <td>1</td>\n",
       "      <td>macro</td>\n",
       "      <td>tumor_109</td>\n",
       "      <td>2482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tumor_110</td>\n",
       "      <td>1</td>\n",
       "      <td>macro</td>\n",
       "      <td>tumor_110</td>\n",
       "      <td>22605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tumor_111</td>\n",
       "      <td>1</td>\n",
       "      <td>micro</td>\n",
       "      <td>tumor_111</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       slide_id  label     class     case_id  nb_patches\n",
       "0    normal_001      0  negative  normal_001        8810\n",
       "1    normal_002      0  negative  normal_002       11605\n",
       "2    normal_003      0  negative  normal_003       27299\n",
       "3    normal_004      0  negative  normal_004        6322\n",
       "4    normal_005      0  negative  normal_005        8766\n",
       "..          ...    ...       ...         ...         ...\n",
       "263   tumor_107      1     micro   tumor_107         196\n",
       "264   tumor_108      1     macro   tumor_108        1530\n",
       "265   tumor_109      1     macro   tumor_109        2482\n",
       "266   tumor_110      1     macro   tumor_110       22605\n",
       "267   tumor_111      1     micro   tumor_111         210\n",
       "\n",
       "[268 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"./dataset_csv/train_data.csv\", index=False)\n",
    "test_df.to_csv(\"./dataset_csv/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import openslide\n",
    "import h5py\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from torcheval.metrics import MulticlassAccuracy, BinaryAccuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class PatchIDCounter:\n",
    "    def __init__(self, df, shuffle=False, cap=None):\n",
    "        self.df = df\n",
    "        self.shuffle = shuffle\n",
    "        self.cap = cap\n",
    "        self.mapping = self._compute_mapping()\n",
    "\n",
    "    def _compute_mapping(self):\n",
    "        np.random.seed(7)\n",
    "        mapping = []\n",
    "        for _, row in self.df.iterrows():\n",
    "            slide_id = row['slide_nb']\n",
    "            nb_of_patches = row['nb_patches']\n",
    "            \n",
    "            # Determine the patch indices we will use\n",
    "            if self.cap and nb_of_patches > self.cap:\n",
    "                selected_patch_indices = np.random.choice(nb_of_patches, self.cap, replace=False)\n",
    "            else:\n",
    "                selected_patch_indices = range(nb_of_patches)\n",
    "            \n",
    "            for patch_id in selected_patch_indices:\n",
    "                mapping.append((slide_id, patch_id))\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(mapping)\n",
    "        return mapping\n",
    "\n",
    "    def next_id(self, idx):\n",
    "        return self.mapping[idx]\n",
    "\n",
    "\n",
    "class PatchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, h5_dir, df, label_dict, image_size, patch_size, cap=100, augmentation=False, training=False, ext=\".tif\"):\n",
    "        if augmentation and training:  \n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(30),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.h5_dir = h5_dir\n",
    "        self.df = df\n",
    "        self.label_dict = label_dict\n",
    "        self.ext = ext\n",
    "        self.patch_size = (patch_size, patch_size)\n",
    "        \n",
    "        self.counter = PatchIDCounter(df, shuffle=training, cap=cap)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.counter.mapping)\n",
    "        # return 10\n",
    "    def __getitem__(self, idx):\n",
    "        slide_id, patch_id = self.counter.next_id(idx)\n",
    "        return slide_id, patch_id\n",
    "        # label = self.df[\"label\"][self.df[\"slide_id\"] == slide_id].item()\n",
    "        \n",
    "        # wsi = openslide.open_slide(os.path.join(self.data_dir, slide_id + self.ext))\n",
    "        # with h5py.File(os.path.join(self.h5_dir, slide_id + \".h5\"), \"r\") as hf:\n",
    "        #     c = np.array(hf[\"coords\"])[patch_id]\n",
    "        # patch = wsi.read_region(c, 0, self.patch_size).convert(\"RGB\")\n",
    "        # return self.transform(patch), np.array(self.label_dict[label])[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8, 5, 0, 2, 1, 9, 7, 3, 6, 4])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "print(np.random.choice(range(100)))\n",
    "np.random.permutation(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': {'values': ['Adam', 'SGD']},\n",
       " 'backbone': {'values': ['resnet50', 'densenet', 'mobilenet', 'vit', 'ctp']},\n",
       " 'finetuning': {'values': [None, 'deep', 'mid', 'shallow']},\n",
       " 'image_size': {'values': [224, 512]},\n",
       " 'lr': {'distribution': 'uniform', 'min': 0.0002, 'max': 0.1},\n",
       " 'l2_reg': {'distribution': 'uniform', 'min': 1e-05, 'max': 0.001},\n",
       " 'data_dir': {'value': '/media/nfs/LN/CAMELYON16/images/'},\n",
       " 'h5_dir': {'value': '/media/nfs/LN/CAMELYON16/patches/'},\n",
       " 'training_csv': {'value': './dataset_csv/train_data.csv'},\n",
       " 'testing_csv': {'value': './dataset_csv/test_data.csv'},\n",
       " 'run_name': {'value': None},\n",
       " 'earlystopping': {'value': 20},\n",
       " 'ext': {'value': '.tif'},\n",
       " 'patch_size': {'value': 224},\n",
       " 'max_patches': {'value': 100},\n",
       " 'augmentation': {'value': True},\n",
       " 'batch_size': {'value': 128},\n",
       " 'val_batch_size': {'value': 64},\n",
       " 'cross_validation': {'value': 5},\n",
       " 'epochs': {'value': 100},\n",
       " 'load_from': {'value': None},\n",
       " 'seed': {'value': 7},\n",
       " 'multi_gpus': {'value': True},\n",
       " 'wandb': {'value': False}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(\n",
    "        data_dir=\"/media/nfs/LN/CAMELYON16/images/\",\n",
    "        h5_dir=\"/media/nfs/LN/CAMELYON16/patches/\",\n",
    "        training_csv=\"./dataset_csv/train_data.csv\",\n",
    "        testing_csv=\"./dataset_csv/test_data.csv\",\n",
    "        run_name=None,\n",
    "        backbone=\"resnet50\",\n",
    "        finetuning=\"mid\",\n",
    "        optimizer=\"Adam\",\n",
    "        lr=1e-3,\n",
    "        l2_reg=1e-5,\n",
    "        earlystopping=20,\n",
    "        image_size=224,\n",
    "        ext=\".tif\",\n",
    "        patch_size=224,\n",
    "        max_patches=100,\n",
    "        augmentation=True,\n",
    "        batch_size=128,\n",
    "        val_batch_size=64,\n",
    "        cross_validation=5,\n",
    "        epochs=100,\n",
    "        load_from=None,\n",
    "        seed=7,\n",
    "        multi_gpus=True,\n",
    "        wandb=False\n",
    "    ):\n",
    "    config = locals()\n",
    "    parameter_dict = {\n",
    "\t\t\t'optimizer': {\n",
    "\t\t\t\t\"values\": ['Adam', 'SGD']\n",
    "\t\t\t},\n",
    "\t\t\t'backbone': {\n",
    "\t\t\t\t\"values\": [\"resnet50\", \"densenet\", \"mobilenet\", \"vit\", \"ctp\"]\n",
    "\t\t\t},\n",
    "            'finetuning': {\n",
    "\t\t\t\t\"values\": [None, \"deep\", \"mid\", \"shallow\"]\n",
    "\t\t\t},\n",
    "            'image_size': {\n",
    "\t\t\t\t\"values\": [224, 512]\n",
    "\t\t\t},\n",
    "\t\t\t'lr': {\n",
    "\t\t\t\t'distribution': 'uniform',\n",
    "\t\t\t\t'min': 2e-4,\n",
    "\t\t\t\t'max': 1e-1\n",
    "\t\t\t},\n",
    "\t\t\t'l2_reg': {\n",
    "\t\t\t\t'distribution': 'uniform',\n",
    "\t\t\t\t'min': 1e-5,\n",
    "\t\t\t\t'max': 1e-3\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "    initial_config = {k: {\"value\": v} for k, v in config.items() if k not in parameter_dict.keys()}\n",
    "    parameter_dict.update(initial_config)\n",
    "    return parameter_dict\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
